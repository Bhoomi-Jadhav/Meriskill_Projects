# -*- coding: utf-8 -*-
"""Diabetes_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AqbbQLKR0EaSgbu_1Upn3abndzs9JeZn
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""##Importing Data"""

data=pd.read_csv("/diabetes.csv")

data.head()

data.info()

data.describe()

"""Checking for missing values"""

sns.heatmap(data.isnull())

sns.set_style("whitegrid")

#visualization of the distribution of the variables

plt.figure(figsize=(15,10))
for i, column in enumerate(data.columns[:-1],1):
  plt.subplot(3,3,i)
  sns.histplot(data[column], bins=30, kde=True, color="skyblue")
  plt.title(f'distribution__{column}')
  plt.xlabel('Column')
  plt.ylabel('frequency')

plt.tight_layout()
plt.show()

# Load your data into a Pandas DataFrame here
df = data

correlation = df.corr()

#visualization the correlation
plt.figure(figsize=(10,8))
sns.heatmap(correlation, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Matrix Correlation")
plt.show()

#Columns that have values of 0 that must be treated
columns_with_zeros=['Glucose', 'BloodPressure', 'SkinThickness','Insulin']

#Replacing 0 values with Nan
for column in columns_with_zeros:
  data[column]=data[column].replace(0,np.nan)

#replacing the Nan with the median of each column
for column in columns_with_zeros:
  data[column].fillna(data[column].median(), inplace=True)

#checking if Nan values still exis in the data set
nan_values=data.isnull().sum()
nan_values

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier

#training,testing and spliting of data
X=data.drop("Outcome",axis=1)
Y=data['Outcome']

#Splitting the dataset into training and testing
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)

#standardization of features
scaler=StandardScaler()
X_train_scaled=scaler.fit_transform(X_train)
X_test_scaled=scaler.transform(X_test)

X_train_scaled.shape, X_test_scaled.shape

#Training the model
model=LogisticRegression(random_state=42)
model.fit(X_train_scaled,Y_train)

#Predictions on the test set
y_pred=model.predict(X_test_scaled)

#Model evaluation
accuracy = accuracy_score(Y_test,y_pred)
conf_matrix = confusion_matrix(Y_test,y_pred)
class_report = classification_report(Y_test,y_pred)

accuracy, conf_matrix, class_report

#Creating and training the Random Forest Model
rf_model=RandomForestClassifier(random_state=42)
rf_model.fit(X_train_scaled,Y_train)

#Prediction on the test set
y_rf_pred = rf_model.predict(X_test_scaled)

#Model Evaluation
rf_accuracy = accuracy_score(Y_test,y_rf_pred)
rf_conf_matrix = confusion_matrix(Y_test,y_rf_pred)
rf_class_report = classification_report(Y_test,y_rf_pred)

rf_accuracy, rf_conf_matrix, rf_class_report

#Process the data
#Set values to 0 for the 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin' columns

columns_with_zeros=['Glucose','BloodPressure', 'SkinThickness', 'Insulin']
for column in columns_with_zeros:
  data[column].replace(0,data[column].median(), inplace=True)

#Split the dataset into features(x) and lables(y)
X=data.drop("Outcome", axis=1)
Y=data['Outcome']

#Spliting the dataset into training and testing
X_train, X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)

#Standardization of features
scaler=StandardScaler()
X_train_scaled=scaler.fit_transform(X_train)
X_test_scaled=scaler.transform(X_test)

#Creating and traning the Random Forest Model
dt_model=DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train_scaled,Y_train)

#Predictions on the test set
y_dt_pred = dt_model.predict(X_test_scaled)

#Model Evaluation
dt_accuracy = accuracy_score(Y_test,y_dt_pred)
#dt_conf_matrix = confusion_matrix(Y_test,y_dt_pred)
dt_class_report = classification_report(Y_test,y_dt_pred)

print("Accuracy:", dt_accuracy)
print("Classification Report:", dt_class_report)

#Importance of Features
feature_importance=dt_model.feature_importances_
for feature, importance in zip(X.columns,feature_importance):
  print(f"Feature:{feature}, Importance:{importance}")